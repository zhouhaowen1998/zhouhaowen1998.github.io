<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Leon.blog</title>
  
  <subtitle>生命不息 脱发不止</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://zhouhaowen1998.github.io/"/>
  <updated>2020-03-04T09:10:47.998Z</updated>
  <id>http://zhouhaowen1998.github.io/</id>
  
  <author>
    <name>周浩文</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>tcp/ip协议知识点速记</title>
    <link href="http://zhouhaowen1998.github.io/2020/03/04/tcp-ip%E5%8D%8F%E8%AE%AE%E7%9F%A5%E8%AF%86%E7%82%B9%E9%80%9F%E8%AE%B0/"/>
    <id>http://zhouhaowen1998.github.io/2020/03/04/tcp-ip协议知识点速记/</id>
    <published>2020-03-04T04:29:49.000Z</published>
    <updated>2020-03-04T09:10:47.998Z</updated>
    
    <content type="html"><![CDATA[<p>今天面试又是一道tcp/ip协议题让我愣了半天，借此机会好好把计算机网络这块好好复习一下。</p><h3>一、TCP/IP模型</h3><br>TCP/IP协议模型（Transmission Control Protocol/Internet Protocol），包含了一系列构成互联网基础的网络协议，是Internet的核心协议。<br><br>基于TCP/IP的参考模型将协议分成四个层次，它们分别是链路层、网络层、传输层和应用层。下图表示TCP/IP模型与OSI模型各层的对照关系。<br><a id="more"></a><br><br><img src="/2020/03/04/tcp-ip%E5%8D%8F%E8%AE%AE%E7%9F%A5%E8%AF%86%E7%82%B9%E9%80%9F%E8%AE%B0/模型图.png" alt><br><br>TCP/IP协议族按照层次由上到下，层层包装。最上面的是应用层，这里面有http，ftp,等等我们熟悉的协议。而第二层则是传输层，著名的TCP和UDP协议就在这个层次。第三层是网络层，IP协议就在这里，它负责对数据加上IP地址和其他的数据以确定传输的目标。第四层是数据链路层，这个层次为待传送的数据加入一个以太网协议头，并进行CRC编码，为最后的数据传输做准备。<br><br><h4>TCP/ip协议封装过程</h4><br><br><img src="/2020/03/04/tcp-ip%E5%8D%8F%E8%AE%AE%E7%9F%A5%E8%AF%86%E7%82%B9%E9%80%9F%E8%AE%B0/数据进入协议栈的封装过程.jpg" alt><br><br>上图清楚地表示了TCP/IP协议中每个层的作用，而TCP/IP协议通信的过程其实就对应着数据入栈与出栈的过程。入栈的过程，数据发送方每层不断地封装首部与尾部，添加一些传输的信息，确保能传输到目的地。出栈的过程，数据接收方每层不断地拆除首部与尾部，得到最终传输的数据。<br><br>下图为以http协议为例子，具体说明<br><img src="/2020/03/04/tcp-ip%E5%8D%8F%E8%AE%AE%E7%9F%A5%E8%AF%86%E7%82%B9%E9%80%9F%E8%AE%B0/Http实例.jpg" alt><br><br><h3>二、数据链路层</h3><p>物理层负责0、1比特流与物理设备电压高低、光的闪灭之间的互换。 数据链路层负责将0、1序列划分为数据帧从一个节点传输到临近的另一个节点,这些节点是通过MAC来唯一标识的(MAC,物理地址，一个主机会有一个MAC地址)。</p><p><img src="/2020/03/04/tcp-ip%E5%8D%8F%E8%AE%AE%E7%9F%A5%E8%AF%86%E7%82%B9%E9%80%9F%E8%AE%B0/数据链路层.jpg" alt></p><ul><li>封装成帧: 把网络层数据报加头和尾，封装成帧,帧头中包括源MAC地址和目的MAC地址。</li><li>透明传输:零比特填充、转义字符。</li><li>可靠传输: 在出错率很低的链路上很少用，但是无线链路WLAN会保证可靠传输。</li><li>差错检测(CRC):接收者检测错误,如果发现差错，丢弃该帧。</li></ul><h3>三、网络层</h3><br><h4>1.IP协议</h4><br><br>IP协议是TCP/IP协议的核心，所有的TCP，UDP，IMCP，IGMP的数据都以IP数据格式传输。要注意的是，IP不是可靠的协议，这是说，IP协议没有提供一种数据未传达以后的处理机制，这被认为是上层协议：TCP或UDP要做的事情。<br><br><h5>1.1IP地址</h5><br><br>在数据链路层中我们一般通过MAC地址来识别不同的节点，而在IP层我们也要有一个类似的地址标识，这就是IP地址。<br><br>32位IP地址分为网络位和地址位，这样做可以减少路由器中路由表记录的数目，有了网络地址，就可以限定拥有相同网络地址的终端都在同一个范围内，那么路由表只需要维护一条这个网络地址的方向，就可以找到相应的这些终端了。<br><br>+ A类IP地址: 0.0.0.0~127.255.255.255<br>+ B类IP地址:128.0.0.0~191.255.255.255<br>+ C类IP地址:192.0.0.0~239.255.255.255<br><br><h5>1.2 IP协议头</h5><br><br><img src="/2020/03/04/tcp-ip%E5%8D%8F%E8%AE%AE%E7%9F%A5%E8%AF%86%E7%82%B9%E9%80%9F%E8%AE%B0/IP协议头.jpg" alt><br><br>这里只介绍:八位的TTL字段。这个字段规定该数据包在穿过多少个路由之后才会被抛弃。某个IP数据包每穿过一个路由器，该数据包的TTL数值就会减少1，当该数据包的TTL成为零，它就会被自动抛弃。<br><br>这个字段的最大值也就是255，也就是说一个协议包也就在路由器里面穿行255次就会被抛弃了，根据系统的不同，这个数字也不一样，一般是32或者是64。<br><br><h5>2.ARP及RARP协议</h5><br><br>ARP 是根据IP地址获取MAC地址的一种协议。<br><br>ARP（地址解析）协议是一种解析协议，本来主机是完全不知道这个IP对应的是哪个主机的哪个接口，当主机要发送一个IP包的时候，会首先查一下自己的ARP高速缓存（就是一个IP-MAC地址对应表缓存）。<br><br>如果查询的IP－MAC值对不存在，那么主机就向网络发送一个ARP协议广播包，这个广播包里面就有待查询的IP地址，而直接收到这份广播的包的所有主机都会查询自己的IP地址，如果收到广播包的某一个主机发现自己符合条件，那么就准备好一个包含自己的MAC地址的ARP包传送给发送ARP广播的主机。<br><br>而广播主机拿到ARP包后会更新自己的ARP缓存（就是存放IP-MAC对应表的地方）。发送广播的主机就会用新的ARP缓存数据准备好数据链路层的的数据包发送工作。<br><br>RARP协议的工作与此相反，不做赘述。<br><br><h5>3.ICMP协议</h5><br>IP协议并不是一个可靠的协议，它不保证数据被送达，那么，自然的，保证数据送达的工作应该由其他的模块来完成。其中一个重要的模块就是ICMP(网络控制报文)协议。ICMP不是高层协议，而是IP层的协议。<br><br>当传送IP数据包发生错误。比如主机不可达，路由不可达等等，ICMP协议将会把错误信息封包，然后传送回给主机。给主机一个处理错误的机会，这 也就是为什么说建立在IP层以上的协议是可能做到安全的原因。<br><br><h3>四、ping</h3><p>ping可以说是ICMP的最著名的应用，是TCP/IP协议的一部分。利用“ping”命令可以检查网络是否连通，可以很好地帮助我们分析和判定网络故障。</p><p>ping这个单词源自声纳定位，而这个程序的作用也确实如此，它利用ICMP协议包来侦测另一个主机是否可达。原理是用类型码为0的ICMP发请 求，受到请求的主机则用类型码为8的ICMP回应。</p><p>ping程序来计算间隔时间，并计算有多少个包被送达。用户就可以判断网络大致的情况。我们可以看到， ping给出来了传送的时间和TTL的数据。</p><h3>五、Traceroute</h3><p>Traceroute是用来侦测主机到目的主机之间所经路由情况的重要工具，也是最便利的工具。</p><p>Traceroute的原理是非常非常的有意思，它收到到目的主机的IP后，首先给目的主机发送一个TTL=1的UDP数据包，而经过的第一个路由器收到这个数据包以后，就自动把TTL减1，而TTL变为0以后，路由器就把这个包给抛弃了，并同时产生 一个主机不可达的ICMP数据报给主机。主机收到这个数据报以后再发一个TTL=2的UDP数据报给目的主机，然后刺激第二个路由器给主机发ICMP数据 报。如此往复直到到达目的主机。这样，traceroute就拿到了所有的路由器IP。</p><h3>六、TCP/UDP</h3><p>TCP/UDP都是是传输层协议，但是两者具有不同的特性，同时也具有不同的应用场景，下面以图表的形式对比分析。</p><p><img src="/2020/03/04/tcp-ip%E5%8D%8F%E8%AE%AE%E7%9F%A5%E8%AF%86%E7%82%B9%E9%80%9F%E8%AE%B0/TCP和UDP区别.jpg" alt></p><p>面向报文:<br>面向报文的传输方式是应用层交给UDP多长的报文，UDP就照样发送，即一次发送一个报文。因此，应用程序必须选择合适大小的报文。若报文太长，则IP层需要分片，降低效率。若太短，会是IP太小。</p><p>面向字节流:<br>面向字节流的话，虽然应用程序和TCP的交互是一次一个数据块（大小不等），但TCP把应用程序看成是一连串的无结构的字节流。TCP有一个缓冲，当应用程序传送的数据块太长，TCP就可以把它划分短一些再传送。</p><p>关于拥塞控制，流量控制，是TCP的重点，后面讲解。</p><p>TCP和UDP协议的一些应用:</p><p><img src="/2020/03/04/tcp-ip%E5%8D%8F%E8%AE%AE%E7%9F%A5%E8%AF%86%E7%82%B9%E9%80%9F%E8%AE%B0/TPC和UDP的应用.jpg" alt></p><p>什么时候应该使用TCP？<br>当对网络通讯质量有要求的时候，比如：整个数据要准确无误的传递给对方，这往往用于一些要求可靠的应用，比如HTTP、HTTPS、FTP等传输文件的协议，POP、SMTP等邮件传输的协议。</p><p>什么时候应该使用UDP？<br>当对网络通讯质量要求不高的时候，要求网络通讯速度能尽量的快，这时就可以使用UDP。</p><h3>七、DNS</h3><p>DNS（Domain Name System，域名系统），因特网上作为域名和IP地址相互映射的一个分布式数据库，能够使用户更方便的访问互联网，而不用去记住能够被机器直接读取的IP数串。通过主机名，最终得到该主机名对应的IP地址的过程叫做域名解析（或主机名解析）。DNS协议运行在UDP协议之上，使用端口号53。</p><h3>八、TCP连接的建立与终止</h3><h4>1.三次握手</h4><p>TCP是面向连接的，无论哪一方向另一方发送数据之前，都必须先在双方之间建立一条连接。在TCP/IP协议中，TCP协议提供可靠的连接服务，连接是通过三次握手进行初始化的。三次握手的目的是同步连接双方的序列号和确认号并交换 TCP窗口大小信息。</p><p><img src="/2020/03/04/tcp-ip%E5%8D%8F%E8%AE%AE%E7%9F%A5%E8%AF%86%E7%82%B9%E9%80%9F%E8%AE%B0/TCP三次握手.jpg" alt><br>第一次握手： 建立连接。客户端发送连接请求报文段，将SYN位置为1，Sequence Number为x；然后，客户端进入SYN_SEND状态，等待服务器的确认；</p><p>第二次握手： 服务器收到SYN报文段。服务器收到客户端的SYN报文段，需要对这个SYN报文段进行确认，设置Acknowledgment Number为x+1(Sequence Number+1)；同时，自己自己还要发送SYN请求信息，将SYN位置为1，Sequence Number为y；服务器端将上述所有信息放到一个报文段（即SYN+ACK报文段）中，一并发送给客户端，此时服务器进入SYN_RECV状态；</p><p>第三次握手： 客户端收到服务器的SYN+ACK报文段。然后将Acknowledgment Number设置为y+1，向服务器发送ACK报文段，这个报文段发送完毕以后，客户端和服务器端都进入ESTABLISHED状态，完成TCP三次握手。</p><h5>为什么要三次握手？</h5><p>为了防止已失效的连接请求报文段突然又传送到了服务端，因而产生错误。</p><p>具体例子：“已失效的连接请求报文段”的产生在这样一种情况下：client发出的第一个连接请求报文段并没有丢失，而是在某个网络结点长时间的滞留了，以致延误到连接释放以后的某个时间才到达server。本来这是一个早已失效的报文段。但server收到此失效的连接请求报文段后，就误认为是client再次发出的一个新的连接请求。于是就向client发出确认报文段，同意建立连接。假设不采用“三次握手”，那么只要server发出确认，新的连接就建立了。由于现在client并没有发出建立连接的请求，因此不会理睬server的确认，也不会向server发送数据。但server却以为新的运输连接已经建立，并一直等待client发来数据。这样，server的很多资源就白白浪费掉了。采用“三次握手”的办法可以防止上述现象发生。例如刚才那种情况，client不会向server的确认发出确认。server由于收不到确认，就知道client并没有要求建立连接。”</p><h4>2.四次挥手</h4><p>当客户端和服务器通过三次握手建立了TCP连接以后，当数据传送完毕，肯定是要断开TCP连接的啊。那对于TCP的断开连接，这里就有了神秘的“四次分手”。</p><p><img src="/2020/03/04/tcp-ip%E5%8D%8F%E8%AE%AE%E7%9F%A5%E8%AF%86%E7%82%B9%E9%80%9F%E8%AE%B0/TCP四次挥手.jpg" alt></p><p>第一次分手： 主机1（可以使客户端，也可以是服务器端），设置Sequence Number，向主机2发送一个FIN报文段；此时，主机1进入FIN_WAIT_1状态；这表示主机1没有数据要发送给主机2了；</p><p>第二次分手： 主机2收到了主机1发送的FIN报文段，向主机1回一个ACK报文段，Acknowledgment Number为Sequence Number加1；主机1进入FIN_WAIT_2状态；主机2告诉主机1，我“同意”你的关闭请求；</p><p>第三次分手： 主机2向主机1发送FIN报文段，请求关闭连接，同时主机2进入LAST_ACK状态；</p><p>第四次分手： 主机1收到主机2发送的FIN报文段，向主机2发送ACK报文段，然后主机1进入TIME_WAIT状态；主机2收到主机1的ACK报文段以后，就关闭连接；此时，主机1等待2MSL后依然没有收到回复，则证明Server端已正常关闭，那好，主机1也可以关闭连接了。</p><h5>为什么要四次分手？</h5><p>TCP协议是一种面向连接的、可靠的、基于字节流的运输层通信协议。TCP是全双工模式，这就意味着，当主机1发出FIN报文段时，只是表示主机1已经没有数据要发送了，主机1告诉主机2，它的数据已经全部发送完毕了；但是，这个时候主机1还是可以接受来自主机2的数据；当主机2返回ACK报文段时，表示它已经知道主机1没有数据发送了，但是主机2还是可以发送数据到主机1的；当主机2也发送了FIN报文段时，这个时候就表示主机2也没有数据要发送了，就会告诉主机1，我也没有数据要发送了，之后彼此就会愉快的中断这次TCP连接。</p><h5>为什么要等待2MSL？</h5><p>MSL：报文段最大生存时间，它是任何报文段被丢弃前在网络内的最长时间。</p><p>原因有二：</p><ul><li>保证TCP协议的全双工连接能够可靠关闭</li><li>保证这次连接的重复数据段从网络中消失</li></ul><p>第一点：如果主机1直接CLOSED了，那么由于IP协议的不可靠性或者是其它网络原因，导致主机2没有收到主机1最后回复的ACK。那么主机2就会在超时之后继续发送FIN，此时由于主机1已经CLOSED了，就找不到与重发的FIN对应的连接。所以，主机1不是直接进入CLOSED，而是要保持TIME_WAIT，当再次收到FIN的时候，能够保证对方收到ACK，最后正确的关闭连接。</p><p>第二点：如果主机1直接CLOSED，然后又再向主机2发起一个新连接，我们不能保证这个新连接与刚关闭的连接的端口号是不同的。也就是说有可能新连接和老连接的端口号是相同的。一般来说不会发生什么问题，但是还是有特殊情况出现：假设新连接和已经关闭的老连接端口号是一样的，如果前一次连接的某些数据仍然滞留在网络中，这些延迟数据在建立新连接之后才到达主机2，由于新连接和老连接的端口号是一样的，TCP协议就认为那个延迟的数据是属于新连接的，这样就和真正的新连接的数据包发生混淆了。所以TCP连接还要在TIME_WAIT状态等待2倍MSL，这样可以保证本次连接的所有数据都从网络中消失。</p><h3>九、TCP流量控制</h3><p>如果发送方把数据发送得过快，接收方可能会来不及接收，这就会造成数据的丢失。所谓流量控制就是让发送方的发送速率不要太快，要让接收方来得及接收。</p><p>利用滑动窗口机制可以很方便地在TCP连接上实现对发送方的流量控制。</p><p>设A向B发送数据。在连接建立时，B告诉了A：“我的接收窗口是 rwnd = 400 ”(这里的 rwnd 表示 receiver window) 。因此，发送方的发送窗口不能超过接收方给出的接收窗口的数值。请注意，TCP的窗口单位是字节，不是报文段。假设每一个报文段为100字节长，而数据报文段序号的初始值设为1。大写ACK表示首部中的确认位ACK，小写ack表示确认字段的值ack。</p><p><img src="/2020/03/04/tcp-ip%E5%8D%8F%E8%AE%AE%E7%9F%A5%E8%AF%86%E7%82%B9%E9%80%9F%E8%AE%B0/TCP流量控制.jpg" alt></p><p>从图中可以看出，B进行了三次流量控制。第一次把窗口减少到 rwnd = 300 ，第二次又减到了 rwnd = 100 ，最后减到 rwnd = 0 ，即不允许发送方再发送数据了。这种使发送方暂停发送的状态将持续到主机B重新发出一个新的窗口值为止。B向A发送的三个报文段都设置了 ACK = 1 ，只有在ACK=1时确认号字段才有意义。</p><p>TCP为每一个连接设有一个持续计时器(persistence timer)。只要TCP连接的一方收到对方的零窗口通知，就启动持续计时器。若持续计时器设置的时间到期，就发送一个零窗口控测报文段（携1字节的数据），那么收到这个报文段的一方就重新设置持续计时器。</p><h3>十、TCP拥塞控制</h3><h4>1.慢开始和拥塞避免</h4><p>发送方维持一个拥塞窗口 cwnd ( congestion window )的状态变量。拥塞窗口的大小取决于网络的拥塞程度，并且动态地在变化。发送方让自己的发送窗口等于拥塞窗口。</p><p>发送方控制拥塞窗口的原则是：只要网络没有出现拥塞，拥塞窗口就再增大一些，以便把更多的分组发送出去。但只要网络出现拥塞，拥塞窗口就减小一些，以减少注入到网络中的分组数。</p><h5>慢开始算法：</h5><p>当主机开始发送数据时，如果立即所大量数据字节注入到网络，那么就有可能引起网络拥塞，因为现在并不清楚网络的负荷情况。</p><p>因此，较好的方法是 先探测一下，即由小到大逐渐增大发送窗口，也就是说，由小到大逐渐增大拥塞窗口数值。</p><p>通常在刚刚开始发送报文段时，先把拥塞窗口 cwnd 设置为一个最大报文段MSS的数值。而在每收到一个对新的报文段的确认后，把拥塞窗口增加至多一个MSS的数值。用这样的方法逐步增大发送方的拥塞窗口 cwnd ，可以使分组注入到网络的速率更加合理。</p><p><img src="/2020/03/04/tcp-ip%E5%8D%8F%E8%AE%AE%E7%9F%A5%E8%AF%86%E7%82%B9%E9%80%9F%E8%AE%B0/慢开始算法.jpg" alt></p><p>每经过一个传输轮次，拥塞窗口 cwnd 就加倍。一个传输轮次所经历的时间其实就是往返时间RTT。不过“传输轮次”更加强调：把拥塞窗口cwnd所允许发送的报文段都连续发送出去，并收到了对已发送的最后一个字节的确认。</p><p>另，慢开始的“慢”并不是指cwnd的增长速率慢，而是指在TCP开始发送报文段时先设置cwnd=1，使得发送方在开始时只发送一个报文段（目的是试探一下网络的拥塞情况），然后再逐渐增大cwnd。</p><p>为了防止拥塞窗口cwnd增长过大引起网络拥塞，还需要设置一个慢开始门限ssthresh状态变量。慢开始门限ssthresh的用法如下：</p><ul><li>当 cwnd &lt; ssthresh 时，使用上述的慢开始算法。</li><li>当 cwnd &gt; ssthresh 时，停止使用慢开始算法而改用拥塞避免算法。</li><li>当 cwnd = ssthresh 时，既可使用慢开始算法，也可使用拥塞控制避免算法。</li></ul><h5>拥塞避免</h5><p>让拥塞窗口cwnd缓慢地增大，即每经过一个往返时间RTT就把发送方的拥塞窗口cwnd加1，而不是加倍。这样拥塞窗口cwnd按线性规律缓慢增长，比慢开始算法的拥塞窗口增长速率缓慢得多。</p><p><img src="/2020/03/04/tcp-ip%E5%8D%8F%E8%AE%AE%E7%9F%A5%E8%AF%86%E7%82%B9%E9%80%9F%E8%AE%B0/拥塞避免.jpg" alt></p><p>无论在慢开始阶段还是在拥塞避免阶段，只要发送方判断网络出现拥塞（其根据就是没有收到确认），就要把慢开始门限ssthresh设置为出现拥塞时的发送 方窗口值的一半（但不能小于2）。然后把拥塞窗口cwnd重新设置为1，执行慢开始算法。</p><p>这样做的目的就是要迅速减少主机发送到网络中的分组数，使得发生 拥塞的路由器有足够时间把队列中积压的分组处理完毕。</p><p>如下图，用具体数值说明了上述拥塞控制的过程。现在发送窗口的大小和拥塞窗口一样大。</p><p><img src="/2020/03/04/tcp-ip%E5%8D%8F%E8%AE%AE%E7%9F%A5%E8%AF%86%E7%82%B9%E9%80%9F%E8%AE%B0/慢启动.jpg" alt></p><h4>2.快重传和快恢复</h4><h5>快重传</h5><p>快重传算法首先要求接收方每收到一个失序的报文段后就立即发出重复确认（为的是使发送方及早知道有报文段没有到达对方）而不要等到自己发送数据时才进行捎带确认。</p><p><img src="/2020/03/04/tcp-ip%E5%8D%8F%E8%AE%AE%E7%9F%A5%E8%AF%86%E7%82%B9%E9%80%9F%E8%AE%B0/快重传.jpg" alt></p><p>接收方收到了M1和M2后都分别发出了确认。现在假定接收方没有收到M3但接着收到了M4。</p><p>显然，接收方不能确认M4，因为M4是收到的失序报文段。根据 可靠传输原理，接收方可以什么都不做，也可以在适当时机发送一次对M2的确认。</p><p>但按照快重传算法的规定，接收方应及时发送对M2的重复确认，这样做可以让 发送方及早知道报文段M3没有到达接收方。发送方接着发送了M5和M6。接收方收到这两个报文后，也还要再次发出对M2的重复确认。这样，发送方共收到了 接收方的四个对M2的确认，其中后三个都是重复确认。</p><p>快重传算法还规定，发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段M3，而不必 继续等待M3设置的重传计时器到期。</p><p>由于发送方尽早重传未被确认的报文段，因此采用快重传后可以使整个网络吞吐量提高约20%。</p><h5>快恢复</h5><p>与快重传配合使用的还有快恢复算法，其过程有以下两个要点：</p><ul><li>当发送方连续收到三个重复确认，就执行“乘法减小”算法，把慢开始门限ssthresh减半。</li><li>与慢开始不同之处是现在不执行慢开始算法（即拥塞窗口cwnd现在不设置为1），而是把cwnd值设置为 慢开始门限ssthresh减半后的数值，然后开始执行拥塞避免算法（“加法增大”），使拥塞窗口缓慢地线性增大。</li></ul><p><img src="/2020/03/04/tcp-ip%E5%8D%8F%E8%AE%AE%E7%9F%A5%E8%AF%86%E7%82%B9%E9%80%9F%E8%AE%B0/快恢复.jpg" alt></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;今天面试又是一道tcp/ip协议题让我愣了半天，借此机会好好把计算机网络这块好好复习一下。&lt;/p&gt;
&lt;h3&gt;一、TCP/IP模型&lt;/h3&gt;&lt;br&gt;TCP/IP协议模型（Transmission Control Protocol/Internet Protocol），包含了一系列构成互联网基础的网络协议，是Internet的核心协议。&lt;br&gt;&lt;br&gt;基于TCP/IP的参考模型将协议分成四个层次，它们分别是链路层、网络层、传输层和应用层。下图表示TCP/IP模型与OSI模型各层的对照关系。&lt;br&gt;
    
    </summary>
    
      <category term="技术" scheme="http://zhouhaowen1998.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="计算机网络" scheme="http://zhouhaowen1998.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>常用的消息中间件入门总结</title>
    <link href="http://zhouhaowen1998.github.io/2020/02/28/%E5%B8%B8%E7%94%A8%E7%9A%84%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6%E5%85%A5%E9%97%A8%E6%80%BB%E7%BB%93/"/>
    <id>http://zhouhaowen1998.github.io/2020/02/28/常用的消息中间件入门总结/</id>
    <published>2020-02-28T13:26:41.000Z</published>
    <updated>2020-03-04T04:08:44.252Z</updated>
    
    <content type="html"><![CDATA[<p>常用的一些消息中间件的入门总结</p><p>MQ主要核心功能是用来处理解耦、异步 、削峰。</p><p>而添加MQ以后也会出现一些缺点：<br>    系统可用性降低 ：当MQ出现问题的时候，相关联系统同时也无法正常接收消息<br>    系统复杂性提高 ：消息重复消费、消息丢失、消息传递的顺序性被打乱<br>    一致性问题      ：数据在传递到MQ后，可能没有发出（或者下流的系统没有接收到）导致数据不一致。 </p><a id="more"></a><p>通过网上一些系统的学习和入门博客，目前大概主流的消息中间件有Activemq rabbitmq rocketmq 以及kafka。<br>下面就是对这些中间件的相关特点进行总结比较<br>ps：这里只是单纯总结，没有实际代码，如果完全没有使用过这些东西，可以去百度搜索入门教程看看。</p><p>下面是对Activemq rabbitmq rocketmq 以及kafka之前的对比</p><table><thead><tr><th style="text-align:left">特性</th><th style="text-align:left">ActiveMQ</th><th style="text-align:left">RabbitMQ</th><th style="text-align:left">RocketMq</th><th style="text-align:left">Kafka</th></tr></thead><tbody><tr><td style="text-align:left">单机吞吐量</td><td style="text-align:left">万级，<br>吞吐量比RocketMQ 、<br> Kafka低了一个数量级</td><td style="text-align:left">万级，<br>吞吐量比RocketMQ、<br> Kafka低了一个数量级</td><td style="text-align:left">十万级，<br>也是一个可以支撑高吞吐的MQ</td><td style="text-align:left">十万级，<br>kafka最大优点就是吞吐量高<br>一般配合大数据类系统机型数据计算和日志采集</td></tr><tr><td style="text-align:left">Topic 数量对吞<br>吐量的影响</td><td style="text-align:left"></td><td style="text-align:left"></td><td style="text-align:left">可以到达几百个，<br>几千个的级别的时候吞吐量时<br>会有较小幅度的下降<br>在同等机器下，<br>可一支撑大量topic</td><td style="text-align:left">从几十个倒带几百个的时候，<br>吞吐量会大幅度下降</td></tr><tr><td style="text-align:left">时效性</td><td style="text-align:left">ms级</td><td style="text-align:left">微秒级，<br>这是最大特点</td><td style="text-align:left">ms级</td><td style="text-align:left">ms级以内</td></tr><tr><td style="text-align:left">可用性</td><td style="text-align:left">高,<br>基于主从架构实现高可用性</td><td style="text-align:left">高,<br>基于主从架构实现高可用性</td><td style="text-align:left">非常高，<br>分布式架构</td><td style="text-align:left">非常高，kafka是分布式的，<br>一个数据多个副本，<br>少数极其宕机，<br>不会丢失数据，<br>不会导致不可用</td></tr><tr><td style="text-align:left">消息可靠性</td><td style="text-align:left">有较低概率丢失数据</td><td style="text-align:left">一般不丢</td><td style="text-align:left">参数优化可以做到0丢失</td><td style="text-align:left">参数优化可以做到0丢失</td></tr><tr><td style="text-align:left">功能支持</td><td style="text-align:left">MQ领域的功能极其完备</td><td style="text-align:left">基于erlang开发，<br>并发能力强，<br>性能好，<br>延时低</td><td style="text-align:left">比较完善，<br>分布式且扩展性好</td><td style="text-align:left">功能较为简单，<br>主要支持简单的MQ功能，<br>在大数据领域的实时计算、<br>日志采集被大规模使用<br>且是事实上的标准</td></tr><tr><td style="text-align:left">优劣势总结</td><td style="text-align:left">技术成熟，功能强大，<br>大量公司和项目都有应用。<br>偶尔会出现较低概率丢失消息。<br>社区现在对5.X维护越来越少，<br>主要是基于解耦和异步来使用，<br>一般大规模吞吐的场景中很少使用</td><td style="text-align:left">Erlang语言开发，性能好，<br>延时低而且开源提供管理界面很好，<br>社区相对比较活跃，<br>几乎每个月都发布几个版本<br>问题也显而易见的，吞吐量比较低，<br>因为他们做的实现机制比较重，<br>Erlang开发在国内没有几个公司<br>很少有实力做源码级别的研究，<br>基本就只能依赖开源社区的维护和修复BUG</td><td style="text-align:left">接口简单应用，<br>日处理量可以上百亿之多，<br>可以做到大规模吞吐，<br>性能非常好分布式扩展也很方便，<br>社区比较比较活跃，<br>可靠性和可用性都是ok的，<br>还能支持大规模的topic数量，<br>支持复杂的MQ业务场景<br>由阿里用JAVA开发，能够自己阅读和掌控<br>但是接口不是按照标椎的JMS规范走的，<br>有些系统迁移需要修改大量代码</td><td style="text-align:left">提供超高的吞吐量和ms级别的延迟，<br>极高的可用性以及可靠性<br>而且分布式可以任意拓展<br>同时kafka最好支撑较少的topic数量<br>保证超高吞吐量<br>缺点就是消息可能重复消费，<br>对数据准确性会造成轻微影响，<br>但以大数据领域中这点影响可以忽略<br>这个特性天然用大数据实时计算和<br>日志收集</td></tr></tbody></table><p>综上所述<br>一般业务引入MQ 大家都用ActiveMQ但是现在现在不建议推荐。<br>后来大家开始用RabbitMQ比较稳定的支持，活跃度也行，中小型公司使用不错。<br>RocketMQ也不错但是要考虑社区突然黄掉的风险，公司对自己技术实力有绝对自信的 能够对RocketMQ有一定研发和掌控的 推荐用RocketMQ。<br>所以中小公司技术实力一般的,技术挑战不高的用RabbitMQ是不错选择。<br>大型公司，基础架构研发实力强的话，用RocketMQ是很好选择。<br>如果是大数据领域的实时计算、日志采集的话,用kafka是业内标准！</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;常用的一些消息中间件的入门总结&lt;/p&gt;
&lt;p&gt;MQ主要核心功能是用来处理解耦、异步 、削峰。&lt;/p&gt;
&lt;p&gt;而添加MQ以后也会出现一些缺点：&lt;br&gt;    系统可用性降低 ：当MQ出现问题的时候，相关联系统同时也无法正常接收消息&lt;br&gt;    系统复杂性提高 ：消息重复消费、消息丢失、消息传递的顺序性被打乱&lt;br&gt;    一致性问题      ：数据在传递到MQ后，可能没有发出（或者下流的系统没有接收到）导致数据不一致。 &lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://zhouhaowen1998.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="消息中间件" scheme="http://zhouhaowen1998.github.io/tags/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
      <category term="java基础" scheme="http://zhouhaowen1998.github.io/tags/java%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>Java中的内存泄露和溢出</title>
    <link href="http://zhouhaowen1998.github.io/2020/02/27/Java%E4%B8%AD%E7%9A%84%E5%86%85%E5%AD%98%E6%B3%84%E9%9C%B2%E5%92%8C%E6%BA%A2%E5%87%BA/"/>
    <id>http://zhouhaowen1998.github.io/2020/02/27/Java中的内存泄露和溢出/</id>
    <published>2020-02-27T12:36:21.000Z</published>
    <updated>2020-03-04T04:07:45.841Z</updated>
    
    <content type="html"><![CDATA[<p>Java中的内存泄露和溢出</p><p>内存溢出：（Out Of Memory—OOM）<br>系统已经不能再分配出你所需要的空间，比如你需要100M的空间，系统只剩90M了，这就叫内存溢出<br>例子：一个盘子用尽各种方法只能装4个果子，你装了5个，结果掉倒地上不能吃了。这就是溢出。比方说栈，栈满时再做进栈必定产生空间溢出，叫上溢，栈空时再做退栈也产生空间溢出，称为下溢。就是分配的内存不足以放下数据项序列,称为内存溢出。说白了就是我承受不了那么多，那我就报错，</p><a id="more"></a><p>内存泄漏：  (Memory Leak)<br>Java有垃圾收集器帮助实现内存自动管理，虽然GC有效的处理了大部分内存，但是并不能完全保证内存的不泄露。</p><p>强引用所指向的对象不会被回收，可能导致内存泄漏，虚拟机宁愿抛出OOM也不会去回收他指向的对象<br>意思就是你用资源的时候为他开辟了一段空间，当你用完时忘记释放资源了，这时内存还被占用着，一次没关系，但是内存泄漏次数多了就会导致内存溢出<br>例子：你向系统申请分配内存进行使用(new)，可是使用完了以后却不归还(delete)，结果你申请到的那块内存你自己也不能再访问（也许你把它的地址给弄丢了），而系统也不能再次将它分配给需要的程序。就相当于你租了个带钥匙的柜子，你存完东西之后把柜子锁上之后，把钥匙丢了或者没有将钥匙还回去，那么结果就是这个柜子将无法供给任何人使用，也无法被垃圾回收器回收，因为找不到他的任何信息。</p><p>2.以发生的方式来分类，内存泄漏可以分为4类： </p><ol><li>常发性内存泄漏。发生内存泄漏的代码会被多次执行到，每次被执行的时候都会导致一块内存泄漏。 </li><li>偶发性内存泄漏。发生内存泄漏的代码只有在某些特定环境或操作过程下才会发生。常发性和偶发性是相对的。对于特定的环境，偶发性的也许就变成了常发性的。所以测试环境和测试方法对检测内存泄漏至关重要。 </li><li>一次性内存泄漏。发生内存泄漏的代码只会被执行一次，或者由于算法上的缺陷，导致总会有一块仅且一块内存发生泄漏。比如，在类的构造函数中分配内存，在析构函数中却没有释放该内存，所以内存泄漏只会发生一次。 </li><li>隐式内存泄漏。程序在运行过程中不停的分配内存，但是直到结束的时候才释放内存。严格的说这里并没有发生内存泄漏，因为最终程序释放了所有申请的内存。但是对于一个服务器程序，需要运行几天，几周甚至几个月，不及时释放内存也可能导致最终耗尽系统的所有内存。所以，我们称这类内存泄漏为隐式内存泄漏。<br>从用户使用程序的角度来看，内存泄漏本身不会产生什么危害，作为一般的用户，根本感觉不到内存泄漏的存在。真正有危害的是内存泄漏的堆积，这会最终消耗尽系统所有的内存。从这个角度来说，一次性内存泄漏并没有什么危害，因为它不会堆积，而隐式内存泄漏危害性则非常大，因为较之于常发性和偶发性内存泄漏它更难被检测到</li></ol><p>内存溢出的原因及解决方法：</p><ol><li>内存溢出原因：<br>1.内存中加载的数据量过于庞大，如一次从数据库取出过多数据；<br>2.集合类中有对对象的引用，使用完后未清空，使得JVM不能回收；<br>3.代码中存在死循环或循环产生过多重复的对象实体；<br>4.使用的第三方软件中的BUG；<br>5.启动参数内存值设定的过小</li><li>内存溢出的原因及解决方法：<br>1.修改JVM启动参数，直接增加内存。(-Xms，-Xmx参数一定不要忘记加。)<br>2.检查错误日志，查看“OutOfMemory”错误前是否有其 它异常或错误。<br>3.对代码进行走查和分析，找出可能发生内存溢出的位置。<br>4.使用内存查看工具动态查看内存使用情况　　</li></ol><p>代码分析找出可能发生内存溢出的位置， 可能出现的几种情况：<br>1、检查对数据库查询中，是否有一次获得全部数据的查询。一般来说，如果一次取十万条记录到内存，就可能引起内存溢出。这个问题比较隐蔽，在上线前，数据库中数据较少，不容易出问题，上线后，数据库中数据多了，一次查询就有可能引起内存溢出。因此对于数据库查询尽量采用分页的方式查询。<br>2、检查代码中是否有死循环或递归调用。<br>3、检查是否有大循环重复产生新对象实体。<br>4、检查List、MAP等集合对象是否有使用完后，未清除的问题。List、MAP等集合对象会始终存有对对象的引用，使得这些对象不能被GC回收。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Java中的内存泄露和溢出&lt;/p&gt;
&lt;p&gt;内存溢出：（Out Of Memory—OOM）&lt;br&gt;系统已经不能再分配出你所需要的空间，比如你需要100M的空间，系统只剩90M了，这就叫内存溢出&lt;br&gt;例子：一个盘子用尽各种方法只能装4个果子，你装了5个，结果掉倒地上不能吃了。这就是溢出。比方说栈，栈满时再做进栈必定产生空间溢出，叫上溢，栈空时再做退栈也产生空间溢出，称为下溢。就是分配的内存不足以放下数据项序列,称为内存溢出。说白了就是我承受不了那么多，那我就报错，&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://zhouhaowen1998.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="JAVA基础" scheme="http://zhouhaowen1998.github.io/tags/JAVA%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>java中的GC回收</title>
    <link href="http://zhouhaowen1998.github.io/2020/02/26/java%E4%B8%AD%E7%9A%84GC%E5%9B%9E%E6%94%B6/"/>
    <id>http://zhouhaowen1998.github.io/2020/02/26/java中的GC回收/</id>
    <published>2020-02-26T14:20:35.000Z</published>
    <updated>2020-03-04T04:07:49.854Z</updated>
    
    <content type="html"><![CDATA[<p>最近准备求职，所以把JAVA一些基础部分从头捞出来复习，所以就大概的网上搜上整理了一些资料。<br>相对于C和C++ Java中的有自带的GC(垃圾回收)机制，不用每次自己手动去调用函数去释放空间。</p><a id="more"></a><p>java中GC回收机制<br>GC（Garbage collection）是Java垃圾回收机制，用于将内存中无用对象进行回收处理。</p><p>基本原理：将内存中不再被使用的对象进行回收，GC中用于回收的方法称为收集器，由于GC需要消耗一些资源和时间，Java在对对象的生命周期特征进行分析后，按照新生代、旧生代的方式来对对象进行收集，以尽可能的缩短GC对应用造成的暂停</p><p>哪些内存需要回收？<br>Java堆和方法区</p><p>运行时数据区的程序计数器、虚拟机栈、本地方法栈都随线程的产生而产生、消灭而消灭。每一个栈帧分配多少内存编译时可知，因此这些区域不需要回收。此外，在堆中，尤其新生代，一次垃圾回收可以回收70%-95%的空间，而方法区的效率远低于此。</p><p>怎么回收？<br>通过垃圾处理器<br>    1.对新生代的对象的收集称为minor GC；<br>    2.对旧生代的对象的收集称为Full GC；<br>    3.程序中主动调用System.gc()强制执行的GC为Full GC。</p><p>何时回收？<br>不同的对象引用类型， GC会采用不同的方法进行回收，JVM对象的引用分为了四种类型：<br>    1.强引用：默认情况下，对象采用的均为强引用（这个对象的实例没有其他对象引用，GC时才会被回收）<br>    2.软引用：软引用是Java中提供的一种比较适合于缓存场景的应用（只有在内存不够用的情况下才会被GC）<br>    3.弱引用：在GC时一定会被GC回收<br>    4.虚引用：由于虚引用只是用来得知对象是否被GC</p><p>垃圾收集算法<br>最基础的算法：<br>分标记和清除两个阶段：首先标记出所需要回收的对象，在标记完成后统一回收所有被标记的对象。<br>不足：效率问题，标记和清除过程都效率不高；空间问题，标记清除之后会产生大量不连续的内存碎片（类似于我们电脑的磁盘碎片），空间碎片太多导致需要分配大对象时无法找到足够的连续内存而不得不提前触发另一次垃圾回收动作。</p><p>复制算法：<br>为了解决效率问题，出现了“复制”算法，他将可用内存按容量划分为大小相等的两块，每次只需要使用其中一块。当一块内存用完了，将还存活的对象复制到另一块上面，然后再把刚刚用完的内存空间一次清理掉。这样就解决了内存碎片问题，但是代价就是可以用内容就缩小为原来的一半。</p><p>标记-整理算法：<br>复制算法在对象存活率较高时就会进行频繁的复制操作，效率将降低。因此又有了标记-整理算法，标记过程同标记-清除算法，但是在后续步骤不是直接对对象进行清理，而是让所有存活的对象都向一侧移动，然后直接清理掉端边界以外的内存。</p><p>分代收集算法：<br>当前商业虚拟机的GC都是采用分代收集算法，这种算法并没有什么新的思想，而是根据对象存活周期的不同将堆分为：新生代和老年代，方法区称为永久代（在新的版本中已经将永久代废弃，引入了元空间的概念，永久代使用的是JVM内存而元空间直接使用物理内存）。这样就可以根据各个年代的特点采用不同的收集算法。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近准备求职，所以把JAVA一些基础部分从头捞出来复习，所以就大概的网上搜上整理了一些资料。&lt;br&gt;相对于C和C++ Java中的有自带的GC(垃圾回收)机制，不用每次自己手动去调用函数去释放空间。&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://zhouhaowen1998.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="JAVA基础" scheme="http://zhouhaowen1998.github.io/tags/JAVA%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>关于此博客</title>
    <link href="http://zhouhaowen1998.github.io/2020/02/25/%E5%85%B3%E4%BA%8E%E6%AD%A4%E5%8D%9A%E5%AE%A2/"/>
    <id>http://zhouhaowen1998.github.io/2020/02/25/关于此博客/</id>
    <published>2020-02-25T12:57:25.000Z</published>
    <updated>2020-02-25T13:06:15.346Z</updated>
    
    <content type="html"><![CDATA[<p>空闲之余利用nexo和github搭建出来这个博客，没有想象中的那么难，但也还有许多地方需要慢慢探索。今后这个博客就用来记录自己的学习过程以及学习中对技术知识点的理解和分析，以便后期对知识的复习和巩固，同时也希望这个微博中的文章能够给来过的朋友带来一些帮助和便利!</p>]]></content>
    
    <summary type="html">
    
      闲下来随手创建的一个博客
    
    </summary>
    
      <category term="默认分类" scheme="http://zhouhaowen1998.github.io/categories/%E9%BB%98%E8%AE%A4%E5%88%86%E7%B1%BB/"/>
    
    
      <category term="声明，规划" scheme="http://zhouhaowen1998.github.io/tags/%E5%A3%B0%E6%98%8E%EF%BC%8C%E8%A7%84%E5%88%92/"/>
    
  </entry>
  
</feed>
